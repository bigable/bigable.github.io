---
layout: post
title: 《百面机器学习》第五章 非监督学习 阅读笔记
category: notes
tag: github
---

**01. K均值聚类**  

聚类：  
在事先不知道任何样本类别标签的情况下，通过数据之间的内在关系把样本划分为若干类别，使得同类别样本之间相似度高，不同类别之间相似度低。聚类是非监督学习。

K均值聚类（K-Means Clustering）：  
通过迭代方式寻找K个簇（Cluster）的一种划分方案，使得聚类结果对应的代价函数最小。

代价函数：  
可以定义为各个样本聚类所属中心点的误差平方和

---  

**问题1. 简述K均值算法的具体步骤**  

K均值聚类的核心目标是将给定的数据集划分为K个簇，并给出每个数据对应的簇中心点。  

算法的具体步骤如下：  

（1）数据预处理，如归一化、离群点处理等  

（2）随机选取K个簇中心  

（3）定义代价函数 J(c,μ)  

（4）令t=0,1,2,...为迭代步数，重复下面过程直到 J 收敛  

&emsp;&emsp;(4.1) 对于每一个样本x<sub>i</sub>，将其分配到距离最近的簇  

&emsp;&emsp;(4.2) 对于每一个类簇k，重新计算该类簇的中心  

**问题2. K均值算法的优缺点是什么？如何对其进行调优**  

* 缺点：  

	（1）受初值和离群点的影响每次的结果不稳定  

	（2）结果通常不是全局最优而是局部最优  

	（3）无法很好地解决数据簇分布差别比较大的情况  

	（4）不太适用于离散分布等  

* 优点：  

	（1）对于大数据及，K均值聚类算法相对是可伸缩和高效的，  
	它的计算复杂度是O(NK<sub>t</sub>)，接近于线性，  
	其中N是数据对象的数据，K是聚类的簇数，t是迭代的轮数  

	（2）以局部最优解结束在一般情况下已经可以满足聚类需求  

* K均值算法的调优：  

	（1）数据归一化和离群点处理  

	（2）合理选择K值  

	（3）采用核函数  

**问题3. 针对K均值算法的缺点，有哪些改进的模型**  

* 缺点：  

	（1）需要人工预先确定初始K值，该值与真实数据分布未必吻合  

	（2）K均值只能收敛到局部最优，效果受初始值影响很大  

	（3）易受到噪点影响  

	（4）样本点只能被划分到单一的类中  

* K-means++算法  

	对初始值选择的改进  

* ISODATA算法  

	当K值大小不确定时使用  

**问题4. 证明K均值算法的收敛性**  
