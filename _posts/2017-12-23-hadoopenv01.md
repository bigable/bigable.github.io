---
layout: post
title: Hadoop手把手逐级搭建(1) Hadoop单机伪分布(single)
category: programming
---

## 第一阶段: Hadoop单机伪分布(single)

### 0. 步骤概述  
```bash  
1). 配置网络修改主机名

2). 配置ssh免密码登录

3). 安装jdk

4). 安装hadoop

5). 配置hadoop单机伪分布运行环境(不使用yarn)

6). 为hadoop单机伪分布增加yarn配置
```  

### 1. 配置网络修改主机名  

1.1 查看VMware虚拟网络  

```bash  
1.1.1 点击VMware菜单“编辑(E)”

1.1.2 在下拉菜单列表选择“虚拟网络编辑器”

1.1.3 在弹出的“虚拟网络编辑器”窗口右下角选择“更改设置(C)”

1.1.4 如果windows弹出的安全提示选择“是”

1.1.5 在窗口上方重新刷新的网络列表里选中“NAT模式”，窗口中间的“WMnet信息”下，复选框会默认选中“NAT模式(与虚拟机共享主机的IP地址)(N)”

1.1.6 点击“NAT设置(S)…”

1.1.7 在弹出的“NAT设置”窗口可以查看到如下信息：
网络VMnet8
子网IP：192.168.111.0
子网掩码：255.255.255.0
网关IP(G)：192.168.111.2

#使用上述信息配置网卡相关属性

```  

1.2 配置虚拟机网卡ifcfg-eth0  

```bash  
1.2.1 打开配置文件ifcfg-eth0
[root@hadoop0 ~]# vi /etc/sysconfig/network-scripts/ifcfg-eth0

1.2.2 删除ifcfg-eth0文件中的如下属性
HWADDR=xx:xx:xx:xx:xx:xx
UUID=xxx

1.2.3 为ifcfg-eth0文件添加如下属性，如已经存在则替换或修改
TYPE=Ethernet
IPADDR=192.168.111.111   #ip地址
NETMASK=255.255.255.0   #子网掩码
GATEWAY=192.168.111.2   #网关
ONBOOT=yes             #随系统自动启动
BOOTPROTO=static        #静态地址

1.2.4 修改完成后/etc/sysconfig/network-scripts/ifcfg-eth0完整内容如下
DEVICE=eth0
NM_CONTROLLED=yes
TYPE=Ethernet
IPADDR=192.168.111.111 
NETMASK=255.255.255.0 
GATEWAY=192.168.111.2 
ONBOOT=yes 
BOOTPROTO=static 

```  

1.3 设置NETWORKING，修改主机名  

```bash  
1.3.1 向/etc/sysconfig/network添加如下内容
[root@hadoop0 ~]# vi /etc/sysconfig/network
NETWORKING=yes      #启动时激活网络
HOSTNAME=hadoop0   #自定义主机名
GATEWAY=192.168.111.2 #网关

1.3.2 修改完成后/etc/sysconfig/network完整内容如下
NETWORKING=yes 
HOSTNAME=hadoop0 
GATEWAY=192.168.111.2 

```

1.4 删除70-persistent-net.rules文件  

```bash  
[root@hadoop0 ~]# rm -rf /etc/udev/rules.d/70-persistent-net.rules

#如果虚拟机克隆自另一台虚拟机，不删除该文件会产生如下错误
device eth0 does not seem to present
```  

1.5 重启网络使配置生效  

```bash  
[root@hadoop0 ~]# service network restart
```  

1.6 测试连接local是否畅通  

```bash  
[root@hadoop0 ~]# ping 127.0.0.1
64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.021 ms
64 bytes from 127.0.0.1: icmp_seq=4 ttl=64 time=0.021 ms

#畅通则持续显示上述内容
```  

1.7 测试连接外网是否畅通  

```bash  
[root@hadoop0 ~]# ping baidu.com
64 bytes from 111.13.101.208: icmp_seq=1 ttl=128 time=5.50 ms
64 bytes from 111.13.101.208: icmp_seq=1 ttl=128 time=5.50 ms

#畅通则持续显示上述内容
```  

1.8 配置resolv.conf  

```bash  
1.8.1 如果ping外网ip地址畅通，ping域名出现如下错误
unknown host baidu.com  
说明配置文件缺少nameserver

1.8.2 向resolv.conf文件添加如下内容
[root@hadoop0 ~]# vi /etc/resolv.conf
nameserver 114.114.114.114
nameserver 8.8.4.4

1.8.3 修改完成后/etc/resolv.conf完整内容如下
nameserver 114.114.114.114
nameserver 8.8.4.4


1.8.4重新测试连接外网域名
[root@hadoop0 ~]# ping baidu.com
64 bytes from 111.13.101.208: icmp_seq=1 ttl=128 time=5.50 ms
64 bytes from 111.13.101.208: icmp_seq=1 ttl=128 time=5.50 ms

#畅通则持续显示上述内容
#其中111.13.101.208是baidu.com解析后的ip地址，可能会有所不同
```  

1.9 关闭防火墙  

```bash  
# 如果测试外网不通，输入如下命令关闭防火墙
1.9.1 临时关闭防火墙
[root@hadoop0 ~]# service iptables off

1.9.2 永久关闭防火墙
[root@hadoop0 ~]# chkconfig iptables off
```  

1.10 在hosts文件中添加主机名映射  

```bash  
1.10.1 为/etc/hosts文件添加如下内容
[root@hadoop0 ~]# vi /etc/hosts
192.168.111.111 hadoop0

1.10.2 添加完成后/etc/hosts文件完整内容如下

127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.111.111 hadoop0

```  

1.11 其他  

```bash  
1.11.1 安装vim
连接网络成功后，如果vim命令不存在，使用如下命令安装vim
[root@hadoop0 ~]# yum install -y vim*

1.11.2 使用xShell连接并操作虚拟机
网络连接成功后，可自行选择使用xShell连接并操作虚拟机，提供了比VMware原生界面更方便的操作
```  

### 2. 设置SSH免密登录  

2.1 生成密匙  

```bash  
[root@hadoop0 ~]# ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa
```  

2.2 查看生成的密匙  

```bash  
[root@hadoop0 ~]# cd ~/.ssh
[root@hadoop0 .ssh]# ls
id_dsa  id_dsa.pub

#在~/.ssh目录下生成了id_dsa和id_dsa.pub两个文件
```  

2.3 测试ssh连接本机  

```bash  
[root@hadoop0 ~]# ssh hadoop0
The authenticity of host 'hadoop0 (192.168.111.111)' can't be established.
RSA key fingerprint is xxx
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'hadoop0,192.168.111.111' (RSA) to the list of known hosts.
root@hadoop0's password:

# ssh连接本机仍需输入密码
```  

2.4 登录自身免密  

```bash  
[root@hadoop0 ~]# cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
```  

2.5 查看结果  

```bash  
2.5.1 进入~/.ssh目录
[root@hadoop0 ~]# cd ~/.ssh

2.5.2 ~/.ssh目录在id_dsa和id_dsa.pub的基础上又新增了authorized_keys
[root@hadoop0 .ssh]# ls
authorized_keys  id_dsa  id_dsa.pub
```  

2.6 验证ssh连接本机  

```bash  
[root@hadoop0 ~]# ssh hadoop0

# 无须再输入密码，表示配置成功
```  

### 3 安装JDK(在虚拟机hadoop0上)  

3.1 在hadoop0上创建目录/usr/java/  

```bash  
[root@hadoop0 ~]# mkdir /usr/java
```  

3.2使用xftp上传jdk-7u67-linux-x64.tar.gz  

```bash  
xftp左侧窗口为windows文件目录;
右侧窗口为当前虚拟机linux文件目录;
从左侧窗口找到windows本地的jdk-7u67-linux-x64.tar.gz;
在右侧窗口进入/usr/java/目录;
左侧窗口双击jdk-7u67-linux-x64.tar.gz文件,即可上传至左侧窗口目前所在的虚拟机目录;
如有问题自行查询xShell和xFtp的使用方法
```  

3.3 解压jdk-7u67-linux-x64.tar.gz到/usr/java  

```bash  
3.3.1 进入/usr/java目录
[root@hadoop0 ~]# cd /usr/java
[root@hadoop0 java]

3.3.2 解压jdk-7u67-linux-x64.tar.gz到/usr/java
[root@hadoop0 java]# tar -zxvf jdk-7u67-linux-x64.tar.gz
```  

3.4 配置java环境变量  

```bash  
# 编辑/etc/profile文件并添加如下内容
[root@hadoop0 ~]# vim /etc/profile
#jdk
export JAVA_HOME=/usr/java/jdk1.7.0_67
export CLASSPATH=.:$JAVA_HOME/lib
export PATH=$JAVA_HOME/bin:$PATH
```  

3.5 使/etc/profile配置生效  

```bash  
[root@hadoop0 ~]# source /etc/profile
```  

3.6 查看java版本，检查环境变量是否生效  

```bash  
[root@hadoop0 ~]# java -version
java version "1.7.0_67"
Java(TM) SE Runtime Environment (build 1.7.0_67-b01)
Java HotSpot(TM) 64-Bit Server VM (build 24.65-b04, mixed mode)

#正常显示如上信息则配置成功
```  

### 4 在hadoop0上配置hadoop环境变量  

4.1 创建/opt/test目录  

```bash  
[root@hadoop0 ~]# mkdir /opt/test
```  

4.2 使用xftp上传hadoop-2.6.5.tar.gz到/opt/test/

4.3 将hadoop-2.6.5.tar.gz解压到文件夹/opt/test/  

```bash  
4.3.1 进入/opt/test目录
[root@hadoop0 ~]# cd /opt/test/
[root@hadoop0 test]#

4.3.2解压hadoop-2.6.5.tar.gz到文件夹/opt/test/
[root@hadoop0 test]# tar -zxvf hadoop-2.6.5.tar.gz
```  

4.4 配置HADOOP环境变量  

```bash  
# 在/etc/profile添加如下内容
[root@hadoop0 test]# vim /etc/profile
#hadoop
export HADOOP_PREFIX=/opt/test/hadoop-2.6.5
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin
```  

4.5使/etc/profile配置生效  

```bash  
[root@hadoop0 test]# source /etc/profile 
```  

4.6 输入hadoop命令查看是否配置成功  

```bash  
[root@hadoop0 test]# hadoop version
Hadoop 2.6.5
…

#出现上述版本号信息表示环境变量配置成功
```  

### 5 配置hadoop单机伪分布运行环境(不使用yarn)  

5.0 进入$HADOOP_HOME/etc/hadoop/目录  

```bash  
[root@hadoop0 ~]# cd /opt/test/hadoop-2.6.5/etc/hadoop/
[root@hadoop0 hadoop]#
```  

5.1在hadoop-env.sh上配置JAVA_HOME  

```bash  
# 为$HADOOP_HOME/etc/hadoop/hadoop-env.sh添加如下内容
[root@hadoop0 hadoop]# vim hadoop-env.sh
export JAVA_HOME=/usr/java/jdk1.7.0_67
```  

5.2 配置core-site.xml  

```bash  
# 将$HADOOP_HOME/etc/hadoop/core-site.xml内容替换如下
[root@hadoop0 hadoop]# vim core-site.xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop0:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/var/test/hadoop/local</value>
</property>
</configuration>
```  

5.3 配置hdfs-site.xml  

```bash  
# 将$HADOOP_HOME/etc/hadoop/hdfs-site.xml内容替换如下
[root@hadoop0 hadoop]# vim hdfs-site.xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop0:50090</value>
    </property>
</configuration>
```  

5.4 配置slaves  

```bash  
5.4.1将原有内容替换为当前虚拟机名称，单机伪分布只配置一台
[root@hadoop0 hadoop]# vim slaves
hadoop0

5.4.2 配置完成后$HADOOP_HOME/etc/hadoop/slaves完整内容如下
hadoop0
```  

5.5 启动hadoop伪分布集群  

```bash  
5.5.1 首次启动格式化namenode
[root@hadoop0 ~]# hdfs namenode -format

5.5.2 启动集群
[root@hadoop0 ~]# start-dfs.sh

5.5.3 查看进程
[root@hadoop0 ~]# jps
2051 SecondaryNameNode
1870 DataNode
1781 NameNode
2159 Jps

5.5.4 查看集群信息
[root@hadoop0 ~]# hadoop fs

5.5.5 查看根目录下的所有内容
[root@hadoop0 ~]# hdfs dfs -ls 
```  

5.6 上传文件测试单机伪分布集群(未使用yarn)  

```bash  
5.6.1 进入$HADOOP_HOME/share/hadoop/mapreduce/目录
[root@hadoop0 ~]# cd /opt/test/hadoop-2.6.5/share/hadoop/mapreduce/

5.6.2 为方便测试直接在mapreduce目录生成测试文件
[root@hadoop0 mapreduce]# echo "hello world hello world hello" >> test.txt

# 或者使用语句生成包含更多内容的文本
for i in `seq 100000`;do echo “hello world hello world $i” >>test.txt;done

5.6.3上传test.txt文件到根目录
5.6.3.1 默认上传
[root@hadoop0 mapreduce]# hadoop fs -put test.txt /

5.6.3.2 也可以指定blocksize
[root@hadoop0 mapreduce]# hdfs dfs -D dfs.blocksize=1048576 -put test.txt /

5.6.4 运行wordcount测试程序
[root@hadoop0 mapreduce]# 
hadoop jar hadoop-mapreduce-examples-2.6.5.jar wordcount /test.txt /output

#其中output是在hdfs文件系统的根目录下创建的输出路径

5.6.5 查看mapreduce运行结果
[root@hadoop0 mapreduce]# hadoop dfs -text /output/part-*
hello	100003
world	200002
“hello	100000
```  

### 6. 为hadoop单机伪分布添加yarn  

6.0 进入$HADOOP_HOME/etc/hadoop目录  

```bash  
[root@hadoop0 ~]# cd /opt/test/hadoop-2.6.5/etc/hadoop/
[root@hadoop0 hadoop]
```  

6.1 分别在mapred-env.sh, yarn-env.sh上配置JAVA_HOME  

```
6.1.1 为$HADOOP_HOME/etc/hadoop/mapred-env.sh添加JAVA_HOME
[root@hadoop0 hadoop]# vim mapred-env.sh
export JAVA_HOME=/usr/java/jdk1.7.0_67

6.1.2 为$HADOOP_HOME/etc/hadoop/yarn-env.sh添加JAVA_HOME
[root@hadoop0 hadoop]# vim yarn-env.sh
export JAVA_HOME=/usr/java/jdk1.7.0_67
```

6.2 配置mapred-site.xml  

```
6.2.1复制一份mapred-site.xml.template并命名为mapred-site.xml
[root@hadoop0 hadoop]# cp mapred-site.xml.template mapred-site.xml

6.2.2 将$HADOOP_HOME/etc/hadoop/mapred-site.xml内容替换如下
[root@hadoop0 hadoop]# vim mapred-site.xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

6.3 配置yarn-site.xml  

```
# 将$HADOOP_HOME/etc/hadoop/yarn-site.xml内容替换如下
[root@hadoop0 hadoop]# vim yarn-site.xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```  

6.4 启动配置了yarn的单机伪分布集群  

```bash  
6.4.1 启动hdfs
[root@hadoop0 ~]# start-dfs.sh

6.4.2 查看进程
[root@hadoop0 ~]# jps
2051 SecondaryNameNode
1870 DataNode
1781 NameNode
2159 Jps

6.4.3 启动yarn
[root@hadoop0 ~]# start-yarn.sh

6.4.4 查看进程
[root@hadoop0 ~]# jps
2051 SecondaryNameNode
1870 DataNode
1781 NameNode
2650 Jps
2291 NodeManager
2203 ResourceManager

# 增加了NodeManager和ResourceManager两个进程
```  

6.5 在运行yarn的单机伪分布集群上测试wordcount程序  

```bash  
6.5.1 进入$HADOOP_HOME/share/hadoop/mapreduce/目录
[root@hadoop0 ~]# cd /opt/test/hadoop-2.6.5/share/hadoop/mapreduce/

6.5.2 运行wordcount测试程序，输出到/output2
[root@hadoop0 mapreduce]# 
hadoop jar hadoop-mapreduce-examples-2.6.5.jar wordcount /test.txt /output2
#运行时会首先看到如下信息
INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032

6.5.3 查看mapreduce运行结果
[root@hadoop0 mapreduce]# hadoop dfs -text /output2/part-*
hello	100003
world	200002
“hello	100000
```  

----------

### 参考资料:  

a). [Hadoop数据分析平台实战——010hadoop介绍安装](https://www.jianshu.com/p/66f5e4ce75c5)

### 后续步骤:    

2). [第二阶段：Hadoop完全分布式(full)](https://bigablecat.github.io/programming/2017/12/27/hadoopenv02/)

3). [第三阶段：Hadoop高可用(HA)](https://bigablecat.github.io/programming/2018/01/03/hadoopenv03/)

4). [第四阶段：Hadoop高可用+联邦+视图文件系统(HA+Federation+ViewFs)](https://bigablecat.github.io/programming/2018/01/05/hadoopenv04/)
